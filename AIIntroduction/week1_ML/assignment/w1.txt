1. DT (Decision Tree, 의사결정나무) 🌳
데이터를 여러 기준에 따라 분기하면서 나무 구조로 분류하는 알고리즘.
특정 조건(예: PetalLength > 2.5cm?)을 기준으로 가지를 나누며 예측.
단순하고 직관적이지만, 과적합(overfitting)될 가능성이 있음.
✔️ 장점: 해석이 쉽고 시각화 가능
❌ 단점: 과적합 가능성이 높음

2. RF (Random Forest, 랜덤 포레스트) 🌲🌲🌲
여러 개의 의사결정나무를 앙상블(ensemble)로 결합하여 예측하는 모델.
데이터 샘플을 랜덤하게 나누어 다수의 의사결정나무를 만들고, 다수결 방식으로 최종 결과 결정.
과적합을 방지하고 더 강력한 예측 성능을 가짐.
✔️ 장점: 과적합 방지, 높은 성능
❌ 단점: 모델이 크고 복잡하여 해석이 어려울 수 있음

3. SVM (Support Vector Machine, 서포트 벡터 머신) ⚡
데이터를 고차원 공간으로 변형하여 두 그룹을 나누는 경계선(초평면, Hyperplane)을 찾음.
데이터가 선형적으로 구분되지 않을 경우, 커널 트릭(Kernel Trick)을 사용하여 비선형 데이터도 분류 가능.
✔️ 장점: 고차원 데이터에서도 강력한 성능
❌ 단점: 계산 비용이 높고, 대량의 데이터에서 느릴 수 있음

4. LR (Logistic Regression, 로지스틱 회귀) 📊
이름은 "회귀"지만 사실은 분류 알고리즘!
시그모이드 함수(0~1)를 이용해 데이터를 두 그룹으로 나누며, 다중 클래스 분류에서는 소프트맥스(Softmax) 함수를 사용.
선형 모델이라 단순하지만, 데이터가 선형적으로 구분되지 않을 경우 성능이 떨어질 수 있음.
✔️ 장점: 해석이 쉽고 빠름
❌ 단점: 데이터가 선형적으로 구분되지 않으면 성능 저하